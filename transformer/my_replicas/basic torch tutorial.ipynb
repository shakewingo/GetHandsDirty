{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588dc8f8-db21-4a3d-9d18-6464cb4110bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368a7383-976f-474f-be57-54cba00ff6be",
   "metadata": {},
   "source": [
    "### Tensor operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7d596a-cdff-46ec-9dd0-ccbdba5c1b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(4,4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 2)\n",
    "display(x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1221c034-44eb-4b6e-81d5-715a0ec7fcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert torch to numpy array\n",
    "x_1 = x.numpy()\n",
    "\n",
    "# !!! Careful: if change in CPU, both objects share memory with each other, so change one will impact the other\n",
    "x.add_(1)\n",
    "display(x, x_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ebb91b-cba5-4eda-94e9-2e9cb7c1f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.from_numpy will share same memory too, while torch.tensor will create a new copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a39363-03d6-4898-91e0-23ef814a5fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU support\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "x = torch.randn(4, 4, device=device)\n",
    "display(device, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63380499-36cc-4b52-bc13-6d7bcfa571dc",
   "metadata": {},
   "source": [
    "### Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32da1c24-d74a-4278-9ef6-c6d08b7f6e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(4, 4, requires_grad=True)\n",
    "y = x+2\n",
    "z = y*y*3\n",
    "z = z.mean()\n",
    "display(x, y, z)\n",
    "display(z.grad_fn)\n",
    "display(x.grad)\n",
    "z.backward()\n",
    "display(x.grad)  # dz/dx\n",
    "\n",
    "# !!! Careful: backward() accumulates the gradients for this tensor into .grad() attributes, so need to be careful for operation considering optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d9b710cb-ca3c-419f-b04d-c0f1df762e63",
   "metadata": {},
   "source": [
    "# Stop a tensor from tracking history\n",
    "1. x.requires_grad_(False)\n",
    "2. x.detach()\n",
    "3. wrap in with torch.no_grad():"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732c4447-16c6-48f1-beca-9572cd0edc31",
   "metadata": {},
   "source": [
    "### Linear regression via tensor operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1018c5ed-d12d-4044-ab89-66daaff7ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3, 4, 5], dtype=torch.float32)\n",
    "y = torch.tensor([2, 4, 6, 8, 10], dtype=torch.float32)\n",
    "# f(x) = 2 * x\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "def loss(y, y_pred):\n",
    "    return ((y_pred - y) ** 2).mean()\n",
    "\n",
    "# training loop\n",
    "lr = 0.01\n",
    "n_epochs = 100\n",
    "i = 0\n",
    "for i in range(n_epochs):\n",
    "    y_pred = forward(x)\n",
    "    l = loss(y, y_pred)\n",
    "    l.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= lr * w.grad\n",
    "    # zero the gradient after updating\n",
    "    w.grad.zero_()\n",
    "    if i % 10 == 0:\n",
    "        display(f'epoch - {i}, weight - {w}, loss - {l}')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec79958-14b5-4b42-bfa2-dd04445ed196",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.tensor([5], dtype=torch.float32)\n",
    "y_pred = forward(x_test)\n",
    "display(f'y_pred is {y_pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738e34e3-d9ee-471b-92b9-5aa54669eb45",
   "metadata": {},
   "source": [
    "### Model, Loss & Optimizer in a \"torch way\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3178483-9015-450d-b85d-6fa2703f20a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# typical training module in a torch way\n",
    "import torch.nn as nn\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c226d5-67bf-4513-bb2a-a23d2e092271",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1], [2], [3], [4], [5]], dtype=torch.float32)\n",
    "y = torch.tensor([[2], [4], [6], [8], [10]], dtype=torch.float32)\n",
    "input_size, output_size = 1, 1\n",
    "model = LinearRegression(input_size, output_size)\n",
    "# y_pred = model(x_test)\n",
    "# display(f'Prediction before training is {y_pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75700149-ce2d-4b8f-8509-b616acae5e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "n_epochs = 150\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# training loop\n",
    "for i in range(n_epochs):\n",
    "    y_pred = model(x)  # automatically execute forward()\n",
    "    l = loss(y_pred, y)\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    w, b = model.parameters()\n",
    "    if i % 10 == 0:\n",
    "       display(f'epoch - {i}, weight, bias - {w}, {b}, loss - {l}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d168086d-529b-4cda-9aef-a76c1ffb6fff",
   "metadata": {},
   "source": [
    "### First NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7995d374-15bd-47d4-822e-646efb72507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leverage GPU, Dataset, DatasetLoader, Transforms, Neural Network, Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574f0fc7-b6b3-4180-a673-501d7fea5401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "input_size = 784 # 28x28\n",
    "hidden_size = 500 \n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "examples = iter(test_loader)\n",
    "example_data, example_targets = next(examples)\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(example_data[i][0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75917e00-ae5f-48dc-bf4d-082b3a45cd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf18021d-910e-4e1f-975e-3e7ce14e885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully-connected with one hidden layer NN\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_dim, num_classes)\n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f46c741-edc9-465d-8e96-5c6f75b30013",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c36244-f1f8-42df-a982-b3f175d960f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss & optimizer\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# training loop\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # origin shape: [100, 1, 28, 28]\n",
    "        # resized: [100, 784]\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        y_pred = model(images)  # automatically execute forward()\n",
    "        l = loss(y_pred, labels)\n",
    "        l.backward() # compute gradient descent\n",
    "        optimizer.step() # update weights based on gradients\n",
    "        optimizer.zero_grad()  # empty gradient descent\n",
    "        if i % 100 == 0:\n",
    "            params = model.parameters()\n",
    "            display(f'epoch - {epoch}, steps - {i} / {n_total_steps}, params - {params}, loss - {l}')\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73908af4-fc5d-424a-a154-e336563fad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "# no need to calculate grads\n",
    "with torch.no_grad():\n",
    "    n_samples = len(test_loader.dataset)\n",
    "    n_correct = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        y_pred = model(images)  # automatically execute forward()\n",
    "\n",
    "        # max returns (output_value ,index)\n",
    "        _, predicted = torch.max(y_pred, 1)\n",
    "        # display(predicted, predicted.shape)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the {n_samples} test images: {100*acc} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5473a9-c9fd-4e26-9673-69a6d342af10",
   "metadata": {},
   "source": [
    "### CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678816c6-9c38-4870-8752-074c890fcf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional / Maxpooling /Save&Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deebacbc-ae7a-4f6a-a32d-27b5c65d466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "# dataset has PILImage images of range [0, 1]. \n",
    "# We transform them to Tensors of normalized range [-1, 1]\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def imshow(imgs):\n",
    "    imgs = imgs / 2 + 0.5   # unnormalize\n",
    "    npimgs = imgs.numpy()\n",
    "    plt.imshow(np.transpose(npimgs, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# one batch of random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "img_grid = torchvision.utils.make_grid(images[0:25], nrow=5)\n",
    "imshow(img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd6b782-3fcf-42b5-bc52-c6c0f9819b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3)\n",
    "        self.fc1 = nn.Linear(64*4*4, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # N, 3, 32, 32\n",
    "        x = F.relu(self.conv1(x))   # -> N, 32, 30, 30\n",
    "        x = self.pool(x)            # -> N, 32, 15, 15\n",
    "        x = F.relu(self.conv2(x))   # -> N, 64, 13, 13\n",
    "        x = self.pool(x)            # -> N, 64, 6, 6\n",
    "        x = F.relu(self.conv3(x))   # -> N, 64, 4, 4\n",
    "        x = torch.flatten(x, 1)     # -> N, 1024\n",
    "        x = F.relu(self.fc1(x))     # -> N, 64\n",
    "        x = self.fc2(x)             # -> N, 10\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63363f98-e587-42f7-b223-958d0c1c9ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
