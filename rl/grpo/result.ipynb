{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b60889c-b224-4b7b-97ff-9536935d647a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 59905), started 0:02:26 ago. (Use '!kill 59905' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-56129b5a76e01482\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-56129b5a76e01482\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be85fabf-ad8f-4484-9edd-2d8d8d86a00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '/rl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "733160ff-360c-4ece-9b3f-e315abdd424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from typing import List, Optional, Tuple, Union\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint\n",
    "from torch import nn\n",
    "import os\n",
    "import gc\n",
    "from torch.utils.data import IterableDataset, Dataset\n",
    "import json\n",
    "import numpy as np\n",
    "from transformers import PreTrainedModel\n",
    "from transformers.modeling_outputs import CausalLMOutputWithPast\n",
    "from transformers import PretrainedConfig\n",
    "from transformers import Trainer, TrainingArguments, AutoModelForCausalLM, AutoTokenizer, DefaultDataCollator, DataCollatorForTokenClassification, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9a78f9e-e545-415f-bb68-367c66ad86d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "    Use below format to answer questions\n",
    "    <think>\n",
    "    your thinking process\n",
    "    </think>\n",
    "    <answer>\n",
    "    your answer\n",
    "    </answer>\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eabbf8bb-fb11-42c0-a7f1-899c27c4c720",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f6a1920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6c6e119-8798-41ef-98d4-7eb97a4e7b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval result\n",
    "# query = \"北京在哪个国家？\"\n",
    "query = \"there are 2 chicken and 3 fish and 4 birds, how many ocean animals in total?\"\n",
    "org_model = AutoModelForCausalLM.from_pretrained(\"../Qwen2.5-1.5B-Instruct\", local_files_only=True).to(device)\n",
    "opt_model = AutoModelForCausalLM.from_pretrained(\"./result/checkpoint_4000\", local_files_only=True).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../Qwen2.5-1.5B-Instruct\", local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3960acdf-f3ac-49eb-bb7d-6389e254e057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\n\\n    Use below format to answer questions\\n    <think>\\n    your thinking process\\n    </think>\\n    <answer>\\n    your answer\\n    </answer>\\n    <|im_end|>\\n<|im_start|>user\\nthere are 2 chicken and 3 fish and 4 birds, how many ocean animals in total?<|im_end|>\\n<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = tokenizer.apply_chat_template(\n",
    "                [\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                    {\"role\": \"user\", \"content\": query},\n",
    "                ],\n",
    "                add_generation_prompt=True,\n",
    "                tokenize=False,\n",
    "            )\n",
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e790b929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To find the total number of ocean animals, we need to add up all the different types of animals.\\n\\nThink: We have chickens, fish, and birds. The question asks for \"ocean animals,\" so let\\'s count each type separately.\\n1. Chickens: There are 2 chickens.\\n2. Fish: There are 3 fish.\\n3. Birds: There are 4 birds.\\n\\nNow, let\\'s add them together:\\n2 (chickens) + 3 (fish) + 4 (birds) = 9 ocean animals in total.\\n\\nAnswer: There are 9 ocean animals in total.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs = tokenizer([input_text], return_tensors=\"pt\").to(org_model.device)\n",
    "\n",
    "generated_ids = org_model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=256\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16d9e238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nTo find the total number of ocean animals, we need to add up all the different types of animals mentioned.\\n</think>\\n<answer>\\nThe total number of ocean animals is 2 + 3 + 4 = 9.\\n</answer>'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids = opt_model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=256\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf00ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer-practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
