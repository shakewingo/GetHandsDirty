{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f918392",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: \n",
    "Date: 25/12/03\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9109be8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets \n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81ff5f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x129e37c70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e9ffcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:16<00:00, 593kB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 164kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:02<00:00, 592kB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 9.86MB/s]\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "# Create a dataloader for the training\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Load the MNIST test set\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94aea739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get first batch\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 5, figsize=(10, 2))\n",
    "for i in range(5):\n",
    "    axes[i].imshow(images[i].squeeze(), cmap='gray')\n",
    "    axes[i].set_title(f'Label: {labels[i].item()}')\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a0ba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build MLP\n",
    "from re import X\n",
    "\n",
    "\n",
    "class BasicMLP(nn.Module):\n",
    "    def __init__(self, hidden_size=100, hidden_size_2=200):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size_2)\n",
    "        self.fc3 = nn.Linear(hidden_size_2, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "53f2a493",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicMLP().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2c5461bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 595/595 [00:00<00:00, 642.09it/s, loss=0.0116]\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "def train(train_loader, model, epochs=1):\n",
    "    total_iterations = 0\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        data_iterator = tqdm(train_loader, desc=f'Epoch {epoch+1}')\n",
    "        num_iterations = 0\n",
    "        loss_sum = 0\n",
    "\n",
    "        for data in data_iterator:\n",
    "            num_iterations += 1\n",
    "            total_iterations += 1\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x.view(-1, 28*28))\n",
    "            loss = nn.CrossEntropyLoss()(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "            avg_loss = loss_sum / num_iterations\n",
    "            data_iterator.set_postfix(loss=avg_loss)\n",
    "train(train_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8a4e44f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get original weights\n",
    "original_weights = {}\n",
    "for name, param in model.named_parameters():\n",
    "    original_weights[name] = param.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3d36b431",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1000/1000 [00:00<00:00, 2435.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.101\n",
      "wrong counts for the digit 0: 980\n",
      "wrong counts for the digit 1: 1135\n",
      "wrong counts for the digit 2: 1032\n",
      "wrong counts for the digit 3: 1010\n",
      "wrong counts for the digit 4: 982\n",
      "wrong counts for the digit 5: 892\n",
      "wrong counts for the digit 6: 958\n",
      "wrong counts for the digit 7: 1028\n",
      "wrong counts for the digit 8: 974\n",
      "wrong counts for the digit 9: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "def test(test_loader, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    wrong_counts = [0 for i in range(10)]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader, desc='Testing'):\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            output = model(x.view(-1, 28*28))\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == y[idx]:\n",
    "                    correct +=1\n",
    "                else:\n",
    "                    wrong_counts[y[idx]] +=1\n",
    "                total +=1\n",
    "    print(f'Accuracy: {round(correct/total, 3)}')\n",
    "    for i in range(len(wrong_counts)):\n",
    "        print(f'wrong counts for the digit {i}: {wrong_counts[i]}')\n",
    "\n",
    "test(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "afc2188a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: W: torch.Size([100, 784]) + B: torch.Size([100])\n",
      "Layer 2: W: torch.Size([200, 100]) + B: torch.Size([200])\n",
      "Layer 3: W: torch.Size([10, 200]) + B: torch.Size([10])\n",
      "Total weights is: 100710\n"
     ]
    }
   ],
   "source": [
    "# Get original weights size\n",
    "total_weights = 0\n",
    "for index, layer in enumerate([model.fc1, model.fc2, model.fc3]):\n",
    "    total_weights += layer.weight.nelement() + layer.bias.nelement()\n",
    "    print(f'Layer {index+1}: W: {layer.weight.shape} + B: {layer.bias.shape}')\n",
    "print(f'Total weights is: {total_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "173d357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: fine-tune w LoRA based on digit 9\n",
    "# Modify parameters according to LoRA\n",
    "class LoRAParametrization(nn.Module):\n",
    "    def __init__(self, features_in, features_out, device, rank=1, alpha=0.01):\n",
    "        super().__init__()\n",
    "        # According to the paper, we use a random Gaussian initialization for A and zero for B, so ∆W = BA is zero at the beginning of training\n",
    "        self.lora_A = nn.Parameter(torch.zeros((rank,features_out)).to(device))\n",
    "        self.lora_B = nn.Parameter(torch.zeros((features_in, rank)).to(device))\n",
    "        nn.init.normal_(self.lora_A, mean=0, std=1)\n",
    "        \n",
    "        # According to the paper,scale ∆Wx by α/r , where α is a constant in r. My understanding: try keep the similiar \"learning_rate\" as rank value changed\n",
    "        # When optimizing with Adam, tuning α is roughly the same as tuning the learning rate if we scale the initialization appropriately. \n",
    "        # As a result, we simply set α to the first r we try and do not tune it. \n",
    "        self.scale = alpha / rank\n",
    "        self.enabled = True\n",
    "\n",
    "    def forward(self, original_weights):\n",
    "        if self.enabled:\n",
    "            # Return W + (B*A)*scale\n",
    "            return original_weights + torch.matmul(self.lora_B, self.lora_A).view(original_weights.shape) * self.scale\n",
    "        else:\n",
    "            return original_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8425fb41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParametrizedLinear(\n",
       "  in_features=200, out_features=10, bias=True\n",
       "  (parametrizations): ModuleDict(\n",
       "    (weight): ParametrizationList(\n",
       "      (0): LoRAParametrization()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the parameters to the network\n",
    "# Refer: https://pytorch.org/tutorials/intermediate/parametrizations.html\n",
    "import torch.nn.utils.parametrize as parametrize\n",
    "\n",
    "def linear_layer_parameterization(layer, device, rank=1, lora_alpha=1):\n",
    "    # Only add the parameterization to the weight matrix, ignore the Bias\n",
    "\n",
    "    # From section 4.2 of the paper:\n",
    "    #   We limit our study to only adapting the attention weights for downstream tasks and freeze the MLP modules (so they are not trained in downstream tasks) both for simplicity and parameter-efficiency.\n",
    "    #   [...]\n",
    "    #   We leave the empirical investigation of [...], and biases to a future work.\n",
    "    \n",
    "    features_in, features_out = layer.weight.shape\n",
    "    return LoRAParametrization(\n",
    "        features_in, features_out, rank=rank, alpha=lora_alpha, device=device\n",
    "    )\n",
    "\n",
    "# Replace fc1 layer's weights to be linear_layer_parameterization's fc1 etc.\n",
    "parametrize.register_parametrization(\n",
    "    model.fc1, \"weight\", linear_layer_parameterization(model.fc1, device)\n",
    ")\n",
    "parametrize.register_parametrization(\n",
    "    model.fc2, \"weight\", linear_layer_parameterization(model.fc2, device)\n",
    ")\n",
    "parametrize.register_parametrization(\n",
    "    model.fc3, \"weight\", linear_layer_parameterization(model.fc3, device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ff6cfe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enable_disable_lora(enabled=True):\n",
    "    for layer in [model.fc1, model.fc2, model.fc3]:\n",
    "        layer.parametrizations[\"weight\"][0].enabled = enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c6e292e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proven that does not alter the original weights but only those introduced by LoRA\n",
    "# Check that the frozen parameters are still unchanged by the finetuning\n",
    "assert torch.all(model.fc1.parametrizations.weight.original == original_weights['fc1.weight'])\n",
    "assert torch.all(model.fc2.parametrizations.weight.original == original_weights['fc2.weight'])\n",
    "assert torch.all(model.fc3.parametrizations.weight.original == original_weights['fc3.weight'])\n",
    "\n",
    "enable_disable_lora(enabled=True)\n",
    "# The new linear1.weight is obtained by the \"forward\" function of our LoRA parametrization\n",
    "# The original weights have been moved to net.linear1.parametrizations.weight.original\n",
    "# More info here: https://pytorch.org/tutorials/intermediate/parametrizations.html#inspecting-a-parametrized-module\n",
    "assert torch.equal(model.fc1.weight, model.fc1.parametrizations.weight.original + (model.fc1.parametrizations.weight[0].lora_B @ model.fc1.parametrizations.weight[0].lora_A) * model.fc1.parametrizations.weight[0].scale)\n",
    "\n",
    "enable_disable_lora(enabled=False)\n",
    "# If we disable LoRA, the linear1.weight is the original one\n",
    "assert torch.equal(model.fc1.weight, original_weights['fc1.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "653b584a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.bias\n",
      "fc1.parametrizations.weight.original\n",
      "fc1.parametrizations.weight.0.lora_A\n",
      "fc1.parametrizations.weight.0.lora_B\n",
      "fc2.bias\n",
      "fc2.parametrizations.weight.original\n",
      "fc2.parametrizations.weight.0.lora_A\n",
      "fc2.parametrizations.weight.0.lora_B\n",
      "fc3.bias\n",
      "fc3.parametrizations.weight.original\n",
      "fc3.parametrizations.weight.0.lora_A\n",
      "fc3.parametrizations.weight.0.lora_B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/595 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=\u001b[32m10\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Fine-tuning\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(train_loader, model, epochs)\u001b[39m\n\u001b[32m     19\u001b[39m output = model(x.view(-\u001b[32m1\u001b[39m, \u001b[32m28\u001b[39m*\u001b[32m28\u001b[39m))\n\u001b[32m     20\u001b[39m loss = nn.CrossEntropyLoss()(output, y)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m optimizer.step()\n\u001b[32m     24\u001b[39m loss_sum += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/transformer-practice/lib/python3.14/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/transformer-practice/lib/python3.14/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/transformer-practice/lib/python3.14/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# Free non-lora parameters and fine-tune\n",
    "for name, param in model.named_parameters():\n",
    "    print(name)\n",
    "    if 'lora' not in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Load the MNIST dataset again, by keeping only the digit 9\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "include_indices = mnist_trainset.targets == 9\n",
    "mnist_trainset.data = mnist_trainset.data[include_indices]\n",
    "mnist_trainset.targets = mnist_trainset.targets[include_indices]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Fine-tuning\n",
    "train(train_loader, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "98772430",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1000/1000 [00:00<00:00, 2411.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.101\n",
      "wrong counts for the digit 0: 980\n",
      "wrong counts for the digit 1: 1135\n",
      "wrong counts for the digit 2: 1032\n",
      "wrong counts for the digit 3: 1010\n",
      "wrong counts for the digit 4: 982\n",
      "wrong counts for the digit 5: 892\n",
      "wrong counts for the digit 6: 958\n",
      "wrong counts for the digit 7: 1028\n",
      "wrong counts for the digit 8: 974\n",
      "wrong counts for the digit 9: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "test(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93cdf64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer-practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
