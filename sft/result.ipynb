{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b60889c-b224-4b7b-97ff-9536935d647a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-83adddbde8ac6cad\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-83adddbde8ac6cad\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "733160ff-360c-4ece-9b3f-e315abdd424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from typing import List, Optional, Tuple, Union\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint\n",
    "from torch import nn\n",
    "import os\n",
    "from torch.utils.data import IterableDataset, Dataset\n",
    "import json\n",
    "import numpy as np\n",
    "from transformers import PreTrainedModel\n",
    "from transformers.modeling_outputs import CausalLMOutputWithPast\n",
    "from transformers import PretrainedConfig\n",
    "from transformers import Trainer, TrainingArguments, AutoModelForCausalLM, AutoTokenizer, DefaultDataCollator, DataCollatorForTokenClassification, AutoConfig\n",
    "from train_llama2_from_scratch import Config, LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f6a1920",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "AutoConfig.register(\"custom_gpt\", Config)\n",
    "AutoModelForCausalLM.register(Config, LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6c6e119-8798-41ef-98d4-7eb97a4e7b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   2,  224, 6211,  369, 2405,  372, 1318,  681,  815]]),\n",
       " 'labels': None}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eval result\n",
    "query = \"北京在哪个国家？\"\n",
    "# query = \"1+1等于几？\"\n",
    "\n",
    "reload_model = AutoModelForCausalLM.from_pretrained('./result/checkpoint-13800').to(device) \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./tokenizer\", use_fast=True)\n",
    "input_ids = [tokenizer.bos_token_id] + tokenizer.encode(query)\n",
    "input_data = {'input_ids': torch.tensor(input_ids, device=device).unsqueeze(0), \"labels\":None} # unsqueeze(0) to insert a dim at index 0 for batch\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e790b929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> 北京在哪个国家？'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_data['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16d9e238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        如果     如果  如果    如果  如果还有  如果  如果  如果  如果  如果   如果  如果   如果 “  如果   如果  如果  如果  如果   如果  如果   如果  如果  如果  如果 \"  如果  如果  如果 \n"
     ]
    }
   ],
   "source": [
    "for token in reload_model.generate(inputs=input_data, eos=tokenizer.eos_token_id, max_new_tokens=100, stream=False):\n",
    "    print(tokenizer.decode(token[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452dd0d0-bdc8-48ee-9b5b-61541644c0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10806227-6543-4b7d-870d-85ed49659c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 北京是首都国家，位于中国。北京；1994年，位于中国内陆，是中国内外重要的经济经济的重要组成部分；北京、上海、外交汇、外交汇处等；北京，是中国的经济经济经济发展和城市经济利益相关的重要经济体系之一。\n"
     ]
    }
   ],
   "source": [
    "reload_model = AutoModelForCausalLM.from_pretrained('./result/sft/checkpoint-6441').to(device)\n",
    "input = f'<s>user\\n{query}</s>\\n<s>assistant\\n'\n",
    "input_ids = tokenizer.encode(input)\n",
    "input_data = {'input_ids': torch.tensor(input_ids, device=device).unsqueeze(0), \"labels\":None} # unsqueeze(0) to insert a dim at index 0 for batch\n",
    "for token in reload_model.generate(inputs=input_data, eos=tokenizer.eos_token_id, max_new_tokens=100, stream=False):\n",
    "    print(tokenizer.decode(token[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1d9b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9c9862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer-practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
