{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b60889c-b224-4b7b-97ff-9536935d647a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-83adddbde8ac6cad\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-83adddbde8ac6cad\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "733160ff-360c-4ece-9b3f-e315abdd424f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yingyao/miniconda3/envs/transformer-practice/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "from typing import List, Optional, Tuple, Union\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint\n",
    "from torch import nn\n",
    "import os\n",
    "from torch.utils.data import IterableDataset, Dataset\n",
    "import json\n",
    "import numpy as np\n",
    "from transformers import PreTrainedModel\n",
    "from transformers.modeling_outputs import CausalLMOutputWithPast\n",
    "from transformers import PretrainedConfig\n",
    "from transformers import Trainer, TrainingArguments, AutoModelForCausalLM, AutoTokenizer, DefaultDataCollator, DataCollatorForTokenClassification, AutoConfig\n",
    "from train_llama2_from_scratch import Config, LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f6a1920",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "AutoConfig.register(\"custom_gpt\", Config)\n",
    "AutoModelForCausalLM.register(Config, LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6c6e119-8798-41ef-98d4-7eb97a4e7b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   2,  731,   14,   20, 6239, 1919,  815]]),\n",
       " 'labels': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eval result\n",
    "query = \"北京在哪个国家？\"\n",
    "query = \"1+1等于几？\"\n",
    "\n",
    "reload_model = AutoModelForCausalLM.from_pretrained('/Users/yingyao/Desktop/Code/GetHandsDirty.nosync/sft/model').to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./tokenizer\", use_fast=True)\n",
    "input_ids = [tokenizer.bos_token_id] + tokenizer.encode(query)\n",
    "input_data = {'input_ids': torch.tensor(input_ids, device=device).unsqueeze(0), \"labels\":None} # unsqueeze(0) to insert a dim at index 0 for batch\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e790b929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> 1+1等于几？'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_data['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16d9e238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>好的，我会试试的。谢谢你的建议，祝你度过一个愉快的时光！<|im_end|> <|im_start|>提取一下文章中有关塑料污染的危害。全球变暖导致的一系列会导致大量污染，如二氧化碳、甲烷和氧化亚流失等。<|im_end|> <|im\n"
     ]
    }
   ],
   "source": [
    "for token in reload_model.generate(inputs=input_data, eos=tokenizer.eos_token_id, max_new_tokens=100, stream=False):\n",
    "    print(tokenizer.decode(token[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452dd0d0-bdc8-48ee-9b5b-61541644c0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10806227-6543-4b7d-870d-85ed49659c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 因此，2只是两只鸟，只需要有2只鸟，它会唯一共有多少只鸟，但需要根据具体的身份来确定。\n",
      "\n",
      "2 = 24只鸟\n",
      "\n",
      "所以答案是：\n",
      "\n",
      "从身到一只鸟是唱歌。\n"
     ]
    }
   ],
   "source": [
    "reload_model = AutoModelForCausalLM.from_pretrained('/Users/yingyao/Desktop/Code/GetHandsDirty.nosync/sft/result/sft/checkpoint-6441').to(device)\n",
    "input = f'<s>user\\n{query}</s>\\n<s>assistant\\n'\n",
    "input_ids = tokenizer.encode(input)\n",
    "input_data = {'input_ids': torch.tensor(input_ids, device=device).unsqueeze(0), \"labels\":None} # unsqueeze(0) to insert a dim at index 0 for batch\n",
    "for token in reload_model.generate(inputs=input_data, eos=tokenizer.eos_token_id, max_new_tokens=100, stream=False):\n",
    "    print(tokenizer.decode(token[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1d9b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab9c9862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 又<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n"
     ]
    }
   ],
   "source": [
    "reload_model = AutoModelForCausalLM.from_pretrained('/Users/yingyao/Desktop/Code/GetHandsDirty.nosync/sft/result/dpo/checkpoint-10').to(device)\n",
    "input = f'<s>user\\n{query}</s>\\n<s>assistant\\n'\n",
    "input_ids = tokenizer.encode(input)\n",
    "input_data = {'input_ids': torch.tensor(input_ids, device=device).unsqueeze(0), \"labels\":None} # unsqueeze(0) to insert a dim at index 0 for batch\n",
    "for token in reload_model.generate(inputs=input_data, eos=tokenizer.eos_token_id, max_new_tokens=100, stream=False):\n",
    "    print(tokenizer.decode(token[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf00ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer-practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
